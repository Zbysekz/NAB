{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import itertools\n",
    "import pandas\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure your choices here: choose detector, profile, and file (dataset) to show in the visualizations.\n",
    "# This is the only file which you should need to edit as a user. \n",
    "\n",
    "detector='htmcore' #choose detector here, ie. 'numenta', 'htmcore'\n",
    "detector_profile = \"standard\" # choose from: \"reward_low_FP_rate\", \"reward_low_FN_rate\", \"standard\"\n",
    "detector_summary_row = \"realTweets/Twitter_volume_CRM.csv\" # select detector summary file row(data file name) \n",
    "# ...from the list produced below, or see `./results/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading summary\n",
    "detector_summary_file = \"../results/\"+str(detector)+\"/\"+str(detector)+\"_\"+str(detector_profile)+\"_scores.csv\"\n",
    "\n",
    "summaryDataFrame = pandas.read_csv(detector_summary_file,index_col=\"File\") \n",
    "assert 'Score' in summaryDataFrame.columns, \"'Score' column missing in data file\"\n",
    "    \n",
    "summaryDataFrame = summaryDataFrame.sort_values(by=['Score'],ascending=False)\n",
    "print(\"Printing scores for selected profile (NaN represents total score):\")\n",
    "print(summaryDataFrame.loc[:, 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add detector result file(a single file for specific data file)\n",
    "path_,file_ = detector_summary_row.split(\"/\")\n",
    "result_file = \"../results/\"+str(detector)+\"/\"+str(path_)+\"/\"+str(detector)+\"_\"+str(file_)\n",
    "assert os.path.isfile(result_file), \"No such file: \"+str(result_file)\n",
    "assert set(['Threshold','TP','TN','FP','FN','Total_Count']).issubset(summaryDataFrame.columns), \"Missing columns in file \"+str(detector_summary_file)\n",
    "\n",
    "TP,TN,FP,FN= None,None,None,None\n",
    "if summaryDataFrame[\"Threshold\"][detector_summary_row].size == 1:\n",
    "        threshold = summaryDataFrame[\"Threshold\"][detector_summary_row]\n",
    "        TP = summaryDataFrame[\"TP\"][detector_summary_row]\n",
    "        TN = summaryDataFrame[\"TN\"][detector_summary_row]\n",
    "        FP = summaryDataFrame[\"FP\"][detector_summary_row]\n",
    "        FN = summaryDataFrame[\"FN\"][detector_summary_row]\n",
    "        total_Count = summaryDataFrame[\"Total_Count\"][detector_summary_row]\n",
    "        standard_score = np.array(summaryDataFrame['Score'][detector_summary_row])\n",
    "else: #TODO is this branch needed?\n",
    "        threshold = summaryDataFrame[\"Threshold\"][detector_summary_row][0]\n",
    "        TP = summaryDataFrame[\"TP\"][detector_summary_row][0]\n",
    "        TN = summaryDataFrame[\"TN\"][detector_summary_row][0]\n",
    "        FP = summaryDataFrame[\"FP\"][detector_summary_row][0]\n",
    "        FN = summaryDataFrame[\"FN\"][detector_summary_row][0]\n",
    "        total_Count = summaryDataFrame[\"Total_Count\"][detector_summary_row][0]\n",
    "        standard_score = np.array(summaryDataFrame['Score'][detector_summary_row][0])\n",
    "        \n",
    "print(\"For result file : \" + result_file)\n",
    "print(\"True Positive (Detected anomalies) : \" + str(TP))\n",
    "print(\"True Negative (Detected non anomalies) : \" + str(TN))\n",
    "print(\"False Positive (False alarms) : \" + str(FP))\n",
    "print(\"False Negative (Anomaly not detected) : \" + str(FN))\n",
    "print(\"Total data points : \" + str(total_Count))\n",
    "print(detector_profile+\" score : \"+str(np.sum(standard_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ploting Result (Note if the plot is not visible please close the tab shutdown notebook and restart)\n",
    "#Reading results file \n",
    "\n",
    "dataframe = pandas.read_csv(result_file)\n",
    "assert set(['timestamp','value','anomaly_score','label']).issubset(dataframe.columns), \"Missing columns in file:\"+str(result_file)+\" columns:\"+str(dataframe.columns)    \n",
    "\n",
    "x = np.array(dataframe['timestamp'])\n",
    "value = np.array(dataframe['value'])\n",
    "anomaly_score = np.array(dataframe['anomaly_score'])\n",
    "anomaly_label = np.array(dataframe['label'])\n",
    "\n",
    "# Plot values, anomaly score and label scaled to values\n",
    "value_max = np.max(value)\n",
    "trace_value = {\"x\": x,\n",
    "             \"y\": value,\n",
    "             \"mode\": 'lines',\n",
    "             \"name\": 'Value'}\n",
    "\n",
    "trace_anomaly_score = {\"x\": x,\n",
    "                  \"y\": anomaly_score*value_max,\n",
    "                  \"mode\": 'lines',\n",
    "                  \"name\": 'Anomaly score'}\n",
    "\n",
    "trace_anomaly_label = {\"x\": x,\n",
    "                  \"y\": anomaly_label*value_max,\n",
    "                  \"mode\": 'lines',\n",
    "                  \"name\": 'Anomaly window'}\n",
    "trace_threshold = {\"x\": x,\n",
    "                  \"y\": np.ones(len(x))*threshold*value_max,\n",
    "                  \"mode\": 'lines',\n",
    "                  \"name\": 'Anomaly threshold'}\n",
    "\n",
    "\n",
    "traces = [trace_value,trace_anomaly_score,trace_threshold,trace_anomaly_label]\n",
    "layout = dict(title = \"Scalled anomaly score with value : \"+result_file,\n",
    "                  xaxis = dict(title = 'X'),\n",
    "                  yaxis = dict(title = 'Value')\n",
    "                 )\n",
    "\n",
    "\n",
    "fig = dict(data=traces, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot, anomalys score, label, and result from benchmark\n",
    "trace_anomaly_score = {\"x\": x,\n",
    "                  \"y\": anomaly_score,\n",
    "                  \"mode\": 'lines',\n",
    "                  \"name\": 'Anomaly score'}\n",
    "\n",
    "trace_anomaly_label = {\"x\": x,\n",
    "                  \"y\": anomaly_label,\n",
    "                  \"mode\": 'lines',\n",
    "                  \"name\": 'Anomaly window'}\n",
    "\n",
    "trace_threshold = {\"x\": x,\n",
    "                  \"y\": np.ones(len(x))*threshold,\n",
    "                  \"mode\": 'lines',\n",
    "                  \"name\": 'Anomaly threshold'}\n",
    "\n",
    "trace_standard_score = {\"x\": x,\n",
    "                  \"y\": standard_score,\n",
    "                  \"mode\": 'lines',\n",
    "                  \"name\": 'standard_score'}\n",
    "\n",
    "traces = [trace_anomaly_score,trace_threshold,trace_anomaly_label,trace_standard_score]\n",
    "layout = dict(title = \"Anomaly score : \"+result_file,\n",
    "                  xaxis = dict(title = 'X'),\n",
    "                  yaxis = dict(title = 'Value', range=[-0.1, 1.1]) #range = anomaly score range [0,1] + some padding\n",
    "                 )\n",
    "\n",
    "fig = dict(data=traces, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your data file to plot\n",
    "data_file = \"../data/realTweets/Twitter_volume_AAPL.csv\"\n",
    "\n",
    "# Plot Data (Note if the plot is not visible please close the tab shutdown notebook and restart)\n",
    "assert os.path.isfile(data_file), \"No such file:\"+str(data_file)\n",
    "dataframe = pandas.read_csv(data_file)\n",
    "\n",
    "assert set(['timestamp','value']).issubset(dataframe.columns), \"Missing columns in file:\"+str(data_file)+\" , cols:\"+str(dataframe.columns)\n",
    "\n",
    "x = np.array(dataframe['timestamp'])\n",
    "y = np.array(dataframe['value'])\n",
    "\n",
    "mean = np.mean(y)\n",
    "\n",
    "trace = {\"x\": x,\n",
    "             \"y\": y,\n",
    "             \"mode\": 'lines',\n",
    "             \"name\": 'Value'}\n",
    "trace_mean = {\"x\": x,\n",
    "                  \"y\": np.ones(len(x))*mean,\n",
    "                  \"mode\": 'lines',\n",
    "                  \"name\": 'Mean'}\n",
    "traces = [trace,trace_mean]\n",
    "layout = dict(title = \"Data plot : \"+data_file,\n",
    "                  xaxis = dict(title = 'X'),\n",
    "                  yaxis = dict(title = 'Value')\n",
    "                 )\n",
    "fig = dict(data=traces, layout=layout)\n",
    "iplot(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
